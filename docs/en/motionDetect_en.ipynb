{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect moving objects in the screen\n",
    "\n",
    "This document is used to analyze whether there are moving or changing objects in the frame, based on openCV.\n",
    "\n",
    "\n",
    "# Import camera function libraries\n",
    "\n",
    "After running the following code block, wait a while and wait for the camera to initialize. After the initialization is successful, a 300x300-sized real-time video screen will appear below the code block.\n",
    "\n",
    "You can right-click on this screen and click `Create New View for Output`, so that you can place the camera screen in the window again. Even if you browse to other part of the document, you can still watch the camera screen at any time. This method applies to other widgets.\n",
    "\n",
    "The initialization may fail due to running this code block multiple times. The solution is already included in `jetbot.Camera`, you only need to restart the Kernel, but be careful not to use the circle arrow above the tab, chances are the camera will still fail to initialize.\n",
    "\n",
    "It is a recommended method to restart the Kernel:\n",
    "In `File Browser` on the left, right-click on the `*.ipynb` file with a green dot in front (the green origin indicates that the Kernel is running), select `Shut Down Kernel`, and you will find a green dot disappears, then close this tab and double-click the `*.ipynb` file that was closed just now to restart the kernel.\n",
    "\n",
    "Run the following code again, and the camera should be initialized normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dda8ebee4547899f42306d75697ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=300, height=300)\n",
    "\n",
    "image_widget = ipywidgets.Image()  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion detection function\n",
    "\n",
    "The motion detection function is based on openCV. OpenCV is pre-installed in Jetpack, so you can run the following code block to import the required function library directly. If you are not using jetpack, you may need to manually install openCV or imutils in the terminal, and use `sudo pip3 install opencv-python` and `sudo pip3 install imutils` to install the  libraries respectively. If there is no error prompting that these two libraries are missing, you can ignore these and proceed directly The next code block runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import datetime\n",
    "\n",
    "# avg is used to save a frame of reference picture (background)\n",
    "# the new picture is compared with it to determine where in the picture has changed.\n",
    "avg = None\n",
    "\n",
    "\n",
    "lastMovtionCaptured = datetime.datetime.now()\n",
    "\n",
    "# Motion detection function\n",
    "def motionDetect(imgInput):\n",
    "    global avg, lastMovtionCaptured\n",
    "    \n",
    "    # Get the current timestamp.\n",
    "    timestamp = datetime.datetime.now()\n",
    "    \n",
    "    # Convert the frame to black and white, which can increase the efficiency of analysis.\n",
    "    gray = cv2.cvtColor(imgInput, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Gaussian blur the frame to avoid misjudgment caused by noise.\n",
    "    gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    # If the reference frame (background) has not been obtained, create a new one.\n",
    "    if avg is None:\n",
    "        avg = gray.copy().astype(\"float\")\n",
    "        return imgInput\n",
    "\n",
    "    # background update.\n",
    "    cv2.accumulateWeighted(gray, avg, 0.5)\n",
    "    \n",
    "    # Compare the difference between the new frame and the background.\n",
    "    frameDelta = cv2.absdiff(gray, cv2.convertScaleAbs(avg))\n",
    "\n",
    "    # Get the outline of the changed area in the frame.\n",
    "    thresh = cv2.threshold(frameDelta, 5, 255,\n",
    "        cv2.THRESH_BINARY)[1]\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "    # There may be more than one area changes in the frame, so you need to use a for loop to get all the contours.\n",
    "    for c in cnts:\n",
    "        # The default here is 30, which is the threshold of the change area. We only analyze the area greater than 800.\n",
    "        # The smaller the value, the more sensitive the motion detection, but it may also detect meaningless noise.\n",
    "        if cv2.contourArea(c) < 30:\n",
    "            continue\n",
    "\n",
    "        # Draw elements, including rectangle and text.\n",
    "        (mov_x, mov_y, mov_w, mov_h) = cv2.boundingRect(c)\n",
    "        cv2.rectangle(imgInput, (mov_x, mov_y), (mov_x+mov_w, mov_y+mov_h), (128, 255, 0), 1)\n",
    "\n",
    "        # Save the current timestamp to mark the time when the change is detected.\n",
    "        lastMovtionCaptured = timestamp\n",
    "\n",
    "    # In order to avoid the high flickering frequency of drawing elements\n",
    "    # within 0.5 seconds after the motion ends, elements stay.\n",
    "    if (timestamp - lastMovtionCaptured).seconds >= 0.5:\n",
    "        cv2.putText(imgInput,\"Motion Detecting\",(10,80), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(128,255,0),1,cv2.LINE_AA)\n",
    "    else:\n",
    "        cv2.putText(imgInput,\"Motion Detected\",(10,80), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,128,255),1,cv2.LINE_AA)\n",
    "    \n",
    "    # Return to the processed frame.\n",
    "    return imgInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process video frames and display\n",
    "\n",
    "After running the following code, you can see that the color of the frame has changed, indicating that the video screen has been successfully processed by the `motionDetect()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(change):\n",
    "    global image_widget\n",
    "    image = change['new']\n",
    "    image_widget.value = bgr8_to_jpeg(motionDetect(image))\n",
    "    \n",
    "execute({'new': camera.value})\n",
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you have run all the code. When an object moves or changes in the frame, the text content will change, and a green rectangle will mark the changed area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn off this processing and stop the camera\n",
    "Run the following code to turn off the image processing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's close the camera conneciton properly so that we can use the camera in the later notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
