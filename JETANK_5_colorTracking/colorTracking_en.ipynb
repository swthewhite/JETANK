{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JETANK ColorTracking\n",
    "\n",
    "This document is used to implement a color tracking function, which tracks bright yellow objects by default.\n",
    "\n",
    "**Note: This document include servos control. When running the code, be careful if there are fragile objects in the range of motion of the robot arm, and keep it away from children. **\n",
    "\n",
    "# Import camera function libraries\n",
    "\n",
    "After running the following code block, wait a while and wait for the camera to initialize. After the initialization is successful, a 300x300-sized real-time video screen will appear below the code block.\n",
    "\n",
    "You can right-click on this screen and click `Create New View for Output`, so that you can place the camera screen in the window again. Even if you browse to other part of the document, you can still watch the camera screen at any time. This method applies to other widgets.\n",
    "\n",
    "The initialization may fail due to running this code block multiple times. The solution is already included in `jetbot.Camera`, you only need to restart the Kernel, but be careful not to use the circle arrow above the tab, chances are the camera will still fail to initialize.\n",
    "\n",
    "It is a recommended method to restart the Kernel:\n",
    "In `File Browser` on the left, right-click on the `*.ipynb` file with a green dot in front (the green origin indicates that the Kernel is running), select `Shut Down Kernel`, and you will find a green dot disappears, then close this tab and double-click the `*.ipynb` file that was closed just now to restart the kernel.\n",
    "\n",
    "Run the following code again, and the camera should be initialized normally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6620f1a1d3b4ee3a933a2e62fd270a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x00\\x00\\x01\\x00\\x01\\x00\\x00\\xff\\xdb\\x00C\\x00\\x02\\x01\\x0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import traitlets\n",
    "import ipywidgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=300, height=300)\n",
    "\n",
    "image_widget = ipywidgets.Image()  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Importing the TTLServo class\n",
    "\n",
    "First, we need to import the library used to control the servos. Before running this code, please note that ttyTHS1 (the serial port for communication between Jetson Nano and the servos) has been occupied by the Jetson Nano system itself by default. If the installation script executes everything normally, it will shut down the service that previously occupied ttyTHS1, and the script will automatically add the 0666 permissions to ttyTHS1.\n",
    "\n",
    "\n",
    "\n",
    "If the previous installation script fails to execute, you may encounter a Permission Denied error when using ttyTHS1 here. If you encounter this error, the following is the solution:\n",
    "- Click the plus sign in the upper left corner of JupyterLab, a new Launcher tab will open, and Terminal in this tab will open the Jetson Nano console.\n",
    "- Enter the following in the console and press Enter.\n",
    "    > sudo chmod 777 /dev/ttyTHS1\n",
    "- Enter Jetpack's default password `jetbot`, and press Enter to confirm the modification permissions.\n",
    "- Right-click on `JETANK_1_servos.ipynb` on the left, and click `Shut Down Kernal`.\n",
    "- Close the current `JETANK_1_servos.ipynb` tab and double-click on the left side `JETANK_1_servos.ipynb` again to run a new Kernal.\n",
    "\n",
    "Then you can select the following code and press Ctrl+Enter to import the library used to control the servos. The following prompt will appear:\n",
    "Succeeded to open the port\n",
    "Succeeded to change the baudrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded to open the port\n",
      "Succeeded to change the baudrate\n"
     ]
    }
   ],
   "source": [
    "from SCSCtrl import TTLServo\n",
    "import time\n",
    "\n",
    "# If the TTL servo communicates too frequently, \n",
    "# there is a certain probability that rx and tx communication errors will be reported.\n",
    "# This defines a delay for a period of time after each communication to avoid excessive communication frequency.\n",
    "servoCtrlTime = 0.001\n",
    "\n",
    "# Turn the No. 1 and No. 5 servos to the initial position.\n",
    "# servo No. 1 controls the PAN axis movement of the camera pan/tilt, turning it horizontally.\n",
    "# servo No. 5 controls the TILT axis movement of the camera pan/tilt, and the upward and downward pitching in the numerical direction.\n",
    "TTLServo.servoAngleCtrl(1, 0, 1, 150)\n",
    "time.sleep(servoCtrlTime)\n",
    "TTLServo.servoAngleCtrl(5, 0, 1, 150)\n",
    "time.sleep(servoCtrlTime)\n",
    "\n",
    "# camera looks up.\n",
    "def cameraUp(speedInput):\n",
    "    TTLServo.servoAngleCtrl(5, -70, 1, speedInput)\n",
    "    time.sleep(servoCtrlTime)\n",
    "\n",
    "# camera looks down.\n",
    "def cameraDown(speedInput):\n",
    "    TTLServo.servoAngleCtrl(5, 25, 1, speedInput)\n",
    "    time.sleep(servoCtrlTime)\n",
    "\n",
    "# camera looks right.\n",
    "def ptRight(speedInput):\n",
    "    TTLServo.servoAngleCtrl(1, 80, 1, speedInput)\n",
    "    time.sleep(servoCtrlTime)\n",
    "\n",
    "# camera looks left.\n",
    "def ptLeft(speedInput):\n",
    "    TTLServo.servoAngleCtrl(1, -80, 1, speedInput)\n",
    "    time.sleep(servoCtrlTime)\n",
    "\n",
    "# camera tilt axis motion stops.\n",
    "def tiltStop():\n",
    "    TTLServo.servoStop(5)\n",
    "    time.sleep(servoCtrlTime)\n",
    "\n",
    "# camera pan axis motion stops.\n",
    "def panStop():\n",
    "    TTLServo.servoStop(1)\n",
    "    time.sleep(servoCtrlTime)\n",
    "\n",
    "# After running the above code block, the No. 1 and No. 5 servo of the camera pan/tilt will slowly rotate to the middle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Color recognition and tracking function\n",
    "\n",
    "In the `ColorSelect` chapter, we introduced how to obtain the HSV value of an object color, and recorded the maximum and minimum values. You can assign the maximum and minimum values to `colorUpper `and `colorLower` , pay attention to the format: `np.array([H, S, V])`.\n",
    "\n",
    "If you don't replace it with your own object color, you can also use the default program to realize color recognition. The default tracking color is a bright yellow object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define the color that needs to be recognized.\n",
    "\n",
    "#Yellow #FFFF00\n",
    "colorUpper = np.array([44, 255, 255])\n",
    "colorLower = np.array([24, 100, 100])\n",
    "\n",
    "# Red FF0000\n",
    "# colorUpper = np.array([180, 255, 255])\n",
    "# colorLower = np.array([160, 100, 100])\n",
    "\n",
    "# Green #00FF00\n",
    "# colorUpper = np.array([50, 255, 255])\n",
    "# colorLower = np.array([70, 200, 100])\n",
    "\n",
    "# Blue #0000FF\n",
    "# colorUpper = np.array([110, 225, 255])\n",
    "# colorLower = np.array([135, 180, 200])\n",
    "\n",
    "# Cyan #00FFFF\n",
    "# colorUpper = np.array([80, 255, 255])\n",
    "# colorLower = np.array([105, 180, 180])\n",
    "\n",
    "# Magenta #FF00FF\n",
    "# colorUpper = np.array([140, 255, 255])\n",
    "# colorLower = np.array([160, 150, 200])\n",
    "\n",
    "\n",
    "# Define the position tolerance of the camera when turning to this object.\n",
    "# The higher the value, the higher the accuracy of the camera when aiming, \n",
    "# but too high a value may also cause the camera to continuously swing.\n",
    "error_tor = 25\n",
    "\n",
    "# This is the P value of the simple PID regulator, \n",
    "# which is the proportional adjustment coefficient of the motion speed.\n",
    "# If this value is too high, it will cause the camera PT motion overshoot, \n",
    "# and if it is too low, it will cause the color tracking response speed to be too slow.\n",
    "PID_P = 3\n",
    "\n",
    "# Color recognition and tracking function.\n",
    "def findColor(imageInput):\n",
    "    # Convert video frames to HSV color space.\n",
    "    hsv = cv2.cvtColor(imageInput, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Create a mask for pixels that match the target color.\n",
    "    mask = cv2.inRange(hsv, colorLower, colorUpper)\n",
    "    \n",
    "    # Erode, this process will remove the relatively \n",
    "    # small area in the mask just selected, which can be understood as denoising.\n",
    "    mask = cv2.erode(mask, None, iterations=2)\n",
    "    \n",
    "    # dilate, the corrosion process just now will cause the large area to become \n",
    "    # smaller and the small area to disappear. This step is to restore the large area to its previous size.\n",
    "    mask = cv2.dilate(mask, None, iterations=2)\n",
    "    \n",
    "    # Obtain the conformed area contour.\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    center = None\n",
    "    \n",
    "    # If there is a matching area, start to control the movement of the steering gear to achieve color tracking.\n",
    "    if len(cnts) > 0:\n",
    "        # Draw text to show that the target has been found.\n",
    "        imageInput = cv2.putText(imageInput,'Target Detected',(10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "        \n",
    "        # Find the contour of the largest area.\n",
    "        c = max(cnts, key=cv2.contourArea)\n",
    "        \n",
    "        # Get the location of the center point of this area and the radius of this area.\n",
    "        ((box_x, box_y), radius) = cv2.minEnclosingCircle(c)\n",
    "        M = cv2.moments(c)\n",
    "        center = (int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"]))\n",
    "        \n",
    "        # X, Y are the center points of the area.\n",
    "        X = int(box_x)\n",
    "        Y = int(box_y)\n",
    "        \n",
    "        # error_X, error_Y are the absolute value of the error \n",
    "        # between the center point of the area and the center point of the frame.\n",
    "        error_Y = abs(150 - Y)\n",
    "        error_X = abs(150 - X)\n",
    "        \n",
    "        # Draw the size and position of this area.\n",
    "        cv2.rectangle(imageInput,(int(box_x-radius),int(box_y+radius)),(int(box_x+radius),int(box_y-radius)),(255,255,255),1)\n",
    "        \n",
    "        if Y < 150 - error_tor:\n",
    "            # Camera looks up.\n",
    "            imageInput = cv2.putText(imageInput,'Looking Up',(10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "            cameraUp(error_Y*PID_P)\n",
    "        elif Y > 150 + error_tor:\n",
    "            # Camera looks down.\n",
    "            imageInput = cv2.putText(imageInput,'Looking Down',(10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "            cameraDown(error_Y*PID_P)\n",
    "        else:\n",
    "            # The error in the vertical direction is less than the tolerance, \n",
    "            # the camera stops moving in the pitch direction.\n",
    "            imageInput = cv2.putText(imageInput,'Y Axis Locked',(10,50), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "            tiltStop()\n",
    "\n",
    "        if X < 150 - error_tor:\n",
    "            # Camera looks left.\n",
    "            imageInput = cv2.putText(imageInput,'Looking Left',(10,80), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "            ptLeft(error_X*PID_P)\n",
    "        elif X > 150 + error_tor:\n",
    "            # Camera looks right.\n",
    "            imageInput = cv2.putText(imageInput,'Looking Right',(10,80), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "            ptRight(error_X*PID_P)\n",
    "        else:\n",
    "            # The error in the horizontal direction is less than the tolerance, \n",
    "            # and the camera stops moving in the horizontal direction.\n",
    "            imageInput = cv2.putText(imageInput,'X Axis Locked',(10,80), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "            panStop()\n",
    "\n",
    "    # If no area matching the target color is found, the camera stops rotating.\n",
    "    else:\n",
    "        imageInput = cv2.putText(imageInput,'Target Detecting',(10,20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(255,255,255),1,cv2.LINE_AA)\n",
    "        tiltStop()\n",
    "        panStop()\n",
    "    \n",
    "    return imageInput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the frame you see will not change after running the following code. Only after the value of `image_widget.value` is changed and the function `camera.observe()` is called can you observe the final effect. The former value is used to display the processed frame, and the latter function is used to call the image processing related methods immediately after the new frame is collected. \n",
    "\n",
    "Run the following code block to turn on the color recognition and tracking function.\n",
    "**Note: This document include servos control. When running the code, be careful if there are fragile objects in the range of motion of the robot arm, and keep it away from children. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(change):\n",
    "    global image_widget\n",
    "    image = change['new']\n",
    "    image_widget.value = bgr8_to_jpeg(findColor(image))\n",
    "    \n",
    "execute({'new': camera.value})\n",
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn off this function processing and stop the camera\n",
    "Run the following code block to turn off the image processing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "tiltStop()\n",
    "panStop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's close the camera conneciton properly so that we can use the camera in the later notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
